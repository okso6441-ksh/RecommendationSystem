## 2013_DcbmR [Deep content-based music recommendation]

![main](./image/main.PNG)

---

### Abstract    

Automatic music recommendation has become an increasingly relevant problem in recent years, since a lot of music is now sold and consumed digitally. 
ìë™ ìŒì•… ì¶”ì²œì€ í˜„ì¬ ë§ì€ ìŒì•…ì´ ë””ì§€í„¸ ë°©ì‹ìœ¼ë¡œ íŒë§¤ë˜ê³  ì†Œë¹„ë˜ê¸° ë•Œë¬¸ì— ìµœê·¼ ëª‡ ë…„ ë™ì•ˆ ì ì  ë” ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì œê°€ë˜ì—ˆìŠµë‹ˆë‹¤.


Most recommender systems rely on collaborative filtering. 
ëŒ€ë¶€ë¶„ì˜ ì¶”ì²œ ì‹œìŠ¤í…œì€ í˜‘ì—… í•„í„°ë§ì— ì˜ì¡´í•©ë‹ˆë‹¤.


However, this approach suffers from the cold start problem: it fails when no usage data is available, so it is not effective for recommending new and unpopular songs. 
ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ ì½œë“œ ìŠ¤íƒ€íŠ¸ â€‹â€‹ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‹¤íŒ¨í•˜ë¯€ë¡œ ìƒˆë¡­ê³  ì¸ê¸°ì—†ëŠ” ë…¸ë˜ë¥¼ ì¶”ì²œí•˜ëŠ” ë° íš¨ê³¼ì ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.


In this paper, we propose to use a latent factor model for recommendation, and predict the latent factors from music audio when they cannot be obtained from usage data. 
ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì¶”ì²œì„ ìœ„í•´ ì ì¬ ìš”ì†Œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , ì‚¬ìš© ë°ì´í„°ì—ì„œ ì–»ì„ ìˆ˜ì—†ëŠ” ìŒì•… ì˜¤ë””ì˜¤ì˜ ì ì¬ ìš”ì†Œë¥¼ ì˜ˆì¸¡í•  ê²ƒì„ ì œì•ˆí•œë‹¤.


We compare a traditional approach using a bag-of-words representation of the audio signals with deep convolutional neural networks, and evaluate the predictions quantitatively and qualitatively on the Million Song Dataset. 
ì‹¬ì¸µ ì»¨ë³¼ ë£¨ì…˜ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ì‹ í˜¸ì˜ ë‹¨ì–´ ëª¨ìŒ í‘œí˜„ì„ ì‚¬ìš©í•˜ëŠ” ì „í†µì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ë¹„êµí•˜ê³  Million Song Datasetì—ì„œ ì˜ˆì¸¡ì„ ì •ëŸ‰ì , ì • ì„±ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.


We show that using predicted latent factors produces sensible recommendations, despite the fact that there is alarge semantic gap between the characteristics of a song that affect user preference  and the corresponding audio signal. 
ì‚¬ìš©ì ì„ í˜¸ë„ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë…¸ë˜ì˜ íŠ¹ì„±ê³¼ í•´ë‹¹ ì˜¤ë””ì˜¤ ì‹ í˜¸ ì‚¬ì´ì— í° ì˜ë¯¸ ì  ì°¨ì´ê°€ ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ì˜ˆì¸¡ ëœ ì ì¬ ìš”ì†Œë¥¼ ì‚¬ìš©í•˜ë©´ í•©ë¦¬ì ì¸ ê¶Œì¥ ì‚¬í•­ì´ ìƒì„±ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.


We also show that recent advances in deep learning translate very well to the music recommendation setting, with deep convolutional neural networks significantly outperforming the traditional approach.
ë˜í•œ ìµœê·¼ ë”¥ ëŸ¬ë‹ì˜ ë°œì „ì€ ìŒì•… ì¶”ì²œ ì„¤ì •ìœ¼ë¡œ ë§¤ìš° ì˜ ë³€í™˜ë˜ë©° ë”¥ ì»¨ë³¼ ë£¨ì…˜ ì‹ ê²½ë§ì€ ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì„ í¬ê²Œ ëŠ¥ê°€í•©ë‹ˆë‹¤.

---

### 1. Introduction
In recent years, the music industry has shifted more and more towards digital distribution through online music stores and streaming services such as iTunes, Spotify, Grooveshark and Google Play.
ìµœê·¼ ëª‡ ë…„ ë™ì•ˆ ìŒì•… ì‚°ì—…ì€ iTunes, Spotify, Grooveshark ë° Google Playì™€ ê°™ì€ ì˜¨ë¼ì¸ ìŒì•… ìƒì  ë° ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ë¥¼ í†µí•´ ë””ì§€í„¸ ë°°í¬ë¡œ ì ì  ë” ì´ë™í–ˆìŠµë‹ˆë‹¤.


As a result, automatic music recommendation has become an increasingly relevant problem: it allows listeners to discover new music that matches their tastes, and enables online music stores to target their wares to the right audience.
ê²°ê³¼ì ìœ¼ë¡œ ìë™ ìŒì•… ì¶”ì²œì€ ì ì  ë” ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì œê°€ë˜ì—ˆìŠµë‹ˆë‹¤.ì´ë¥¼ í†µí•´ ì²­ì·¨ìëŠ” ìì‹ ì˜ ì·¨í–¥ì— ë§ëŠ” ìƒˆë¡œìš´ ìŒì•…ì„ ë°œê²¬ í•  ìˆ˜ ìˆê³  ì˜¨ë¼ì¸ ìŒì•… ìƒì ì—ì„œ ì ì ˆí•œ ì²­ì¤‘ì—ê²Œ ìì‹ ì˜ ì œí’ˆì„ íƒ€ê²ŸíŒ… í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


Although recommender systems have been studied extensively, the problem of music recommendation in particular is complicated by the sheer variety of different styles and genres, as well as social and geographic factors that influence listener preferences. 
ì¶”ì²œ ì‹œìŠ¤í…œì´ ê´‘ë²”ìœ„í•˜ê²Œ ì—°êµ¬ë˜ì—ˆì§€ë§Œ íŠ¹íˆ ìŒì•… ì¶”ì²œì˜ ë¬¸ì œëŠ” ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ê³¼ ì¥ë¥´ë¿ë§Œ ì•„ë‹ˆë¼ ì²­ì·¨ìì˜ ì„ í˜¸ë„ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì‚¬íšŒì  ë° ì§€ë¦¬ì  ìš”ì¸ìœ¼ë¡œ ì¸í•´ ë³µì¡í•©ë‹ˆë‹¤.


The number of different items that can be recommended is very large, especially when recommending individual songs. 
íŠ¹íˆ ê°œë³„ ê³¡ì„ ì¶”ì²œ í•  ë•Œ ì¶”ì²œ í•  ìˆ˜ìˆëŠ” í•­ëª©ì˜ ìˆ˜ê°€ ë§¤ìš° ë§ìŠµë‹ˆë‹¤.


This number can be reduced by recommending albums or artists instead, but this is not always compatible with the intended use of the system (e.g. automatic playlist generation), and it disregards the fact that the repertoire of an artist is rarely homogenous: listeners may enjoy particular songs more than others.
ëŒ€ì‹  ì•¨ë²”ì´ë‚˜ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì¶”ì²œí•˜ì—¬ì´ ìˆ˜ë¥¼ ì¤„ì¼ ìˆ˜ ìˆì§€ë§Œ ì´ëŠ” ì‹œìŠ¤í…œì˜ ì˜ë„ ëœ ìš©ë„ (ì˜ˆ : ìë™ ì¬ìƒ ëª©ë¡ ìƒì„±)ì™€ í•­ìƒ í˜¸í™˜ë˜ëŠ” ê²ƒì€ ì•„ë‹ˆë©° ì•„í‹°ìŠ¤íŠ¸ì˜ ë ˆí¼í† ë¦¬ê°€ ê±°ì˜ ë™ì¼í•˜ì§€ ì•Šë‹¤ëŠ” ì‚¬ì‹¤ì„ ë¬´ì‹œí•©ë‹ˆë‹¤. ì²­ì·¨ìëŠ” ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë…¸ë˜ë³´ë‹¤ ë” ë§ì€ íŠ¹ì • ë…¸ë˜.


Many recommender systems rely on usage patterns: the combinations of items that users have consumed or rated provide information about the usersâ€™ preferences, and how the items relate to each other. 
ë§ì€ ì¶”ì²œ ì‹œìŠ¤í…œì€ ì‚¬ìš© íŒ¨í„´ì— ì˜ì¡´í•©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì†Œë¹„í•˜ê±°ë‚˜ í‰ê°€ í•œ í•­ëª©ì˜ ì¡°í•©ì€ ì‚¬ìš©ìì˜ ì„ í˜¸ë„ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³  í•­ëª©ì´ ì„œë¡œ ê´€ë ¨ë˜ëŠ” ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤.

This is the collaborative filtering approach. 
ì´ê²ƒì´ í˜‘ì—… í•„í„°ë§ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤.


Another approach is to predict user preferences from item content and metadata.
ë˜ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì€ í•­ëª© ì½˜í…ì¸  ë° ë©”íƒ€ ë°ì´í„°ì—ì„œ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.


The consensus is that collaborative filtering will generally outperform content-based recommendation [1]. 
í•©ì˜ ëœ ì ì€ í˜‘ì—… í•„í„°ë§ì´ ì¼ë°˜ì ìœ¼ë¡œ ì½˜í…ì¸  ê¸°ë°˜ ê¶Œì¥ ì‚¬í•­ì„ ëŠ¥ê°€í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤ [1].


However, it is only applicable when usage data is available. 
ë‹¨, ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ìˆëŠ” ê²½ìš°ì—ë§Œ ì ìš©ë©ë‹ˆë‹¤.


Collaborative filtering suffers from the cold start problem: new items that have not been consumed before cannot be recommended. 
í˜‘ì—… í•„í„°ë§ì€ ì½œë“œ ìŠ¤íƒ€íŠ¸ ë¬¸ì œë¡œ ì¸í•´ ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ì „ì— ì†Œë¹„ë˜ì§€ ì•Šì€ ìƒˆ í•­ëª©ì€ ê¶Œì¥ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.


Additionally, items that are only of interest to a niche audience are more difficult to recommend because usage data is scarce. 
ë˜í•œ ì‚¬ìš© ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê¸° ë•Œë¬¸ì— í‹ˆìƒˆ ê³ ê°ì—ê²Œë§Œ ê´€ì‹¬ì´ìˆëŠ” í•­ëª©ì€ ì¶”ì²œí•˜ê¸°ê°€ ë” ì–´ë µìŠµë‹ˆë‹¤.


In many domains, and especially in music, they comprise the majority of the available items, because the usersâ€™ consumption patterns follow a power law [2]. 
ì‚¬ìš©ìì˜ ì†Œë¹„ íŒ¨í„´ì´ ì „ë ¥ ë²•ì¹™ì„ ë”°ë¥´ê¸° ë•Œë¬¸ì— ë§ì€ ì˜ì—­, íŠ¹íˆ ìŒì•…ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•­ëª©ì˜ ëŒ€ë¶€ë¶„ì„ êµ¬ì„±í•©ë‹ˆë‹¤ [2].


Content-based recommendation is not affected by these issues.
ì½˜í…ì¸  ê¸°ë°˜ ê¶Œì¥ ì‚¬í•­ì€ ì´ëŸ¬í•œ ë¬¸ì œì˜ ì˜í–¥ì„ë°›ì§€ ì•ŠìŠµë‹ˆë‹¤.

#### 1.1 Content-based music recommendation

Music can be recommended based on available metadata: information such as the artist, album and year of release is usually known. 
ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íƒ€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìŒì•…ì„ ì¶”ì²œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì•„í‹°ìŠ¤íŠ¸, ì•¨ë²” ë° ì¶œì‹œ ì—°ë„ì™€ ê°™ì€ ì •ë³´ê°€ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.


Unfortunately this will lead to predictable recommendations. 
ë¶ˆí–‰íˆë„ ì´ê²ƒì€ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê¶Œì¥ ì‚¬í•­ìœ¼ë¡œ ì´ì–´ì§ˆ ê²ƒì…ë‹ˆë‹¤.


For example, recommending songs by artists that the user is known to enjoy is not particularly useful.
ì˜ˆë¥¼ ë“¤ì–´ ì‚¬ìš©ìê°€ ì¢‹ì•„í•˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì§„ ì•„í‹°ìŠ¤íŠ¸ì˜ ë…¸ë˜ë¥¼ ì¶”ì²œí•˜ëŠ” ê²ƒì€ íŠ¹ë³„íˆ ìœ ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.


One can also attempt to recommend music that is perceptually similar to what the user has previously listened to, by measuring the similarity between audio signals [3, 4]. 
ì˜¤ë””ì˜¤ ì‹ í˜¸ ê°„ì˜ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ì—¬ ì‚¬ìš©ìê°€ ì´ì „ì—ë“¤ì€ ê²ƒê³¼ ì§€ê° ì ìœ¼ë¡œ ìœ ì‚¬í•œ ìŒì•…ì„ ì¶”ì²œ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ [3, 4].


This approach requires the definition of a suitable similarity metric. 
ì´ ì ‘ê·¼ ë°©ì‹ì—ëŠ” ì ì ˆí•œ ìœ ì‚¬ì„± ë©”íŠ¸ë¦­ì˜ ì •ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.


Such metrics are often defined ad hoc, based on prior knowledge about music audio, and as a result they are not necessarily optimal for the task of music recommendation. 
ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì€ ì¢…ì¢… ìŒì•… ì˜¤ë””ì˜¤ì— ëŒ€í•œ ì‚¬ì „ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì„ì‹œë¡œ ì •ì˜ë˜ë©° ê²°ê³¼ì ìœ¼ë¡œ ìŒì•… ì¶”ì²œ ì‘ì—…ì— ë°˜ë“œì‹œ ìµœì  ì¸ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.


Because of this, some researchers have used user preference data to tune similarity metrics [5, 6].
ì´ ë•Œë¬¸ì— ì¼ë¶€ ì—°êµ¬ìë“¤ì€ ìœ ì‚¬ì„± ë©”íŠ¸ë¦­ì„ ì¡°ì •í•˜ê¸° ìœ„í•´ ì‚¬ìš©ì ì„ í˜¸ë„ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤ [5, 6].

#### 1.2 Collaborative filtering

Collaborative filtering methods can be neighborhood-based or model-based [7]. 
í˜‘ì—… í•„í„°ë§ ë°©ë²•ì€ ì´ì›ƒ ê¸°ë°˜ ë˜ëŠ” ëª¨ë¸ ê¸°ë°˜ ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ [7].


The former methods rely on a similarity measure between users or items: they recommend items consumed by other users with similar preferences, or similar items to the ones that the user has already consumed. 
ì „ìì˜ ë°©ë²•ì€ ì‚¬ìš©ì ë˜ëŠ” í•­ëª© ê°„ì˜ ìœ ì‚¬ì„± ì¸¡ì •ì— ì˜ì¡´í•©ë‹ˆë‹¤. ìœ ì‚¬í•œ ì„ í˜¸ë„ë¥¼ ê°€ì§„ ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ì†Œë¹„ í•œ í•­ëª© ë˜ëŠ” ì‚¬ìš©ìê°€ ì´ë¯¸ ì†Œë¹„ í•œ í•­ëª©ê³¼ ìœ ì‚¬í•œ í•­ëª©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.


Modelbased methods on the other hand attempt to model latent characteristics of the users and items, which are usually represented as vectors of latent factors. 
ë°˜ë©´ì— ëª¨ë¸ ê¸°ë°˜ ë°©ë²•ì€ ì¼ë°˜ì ìœ¼ë¡œ ì ì¬ ìš”ì¸ì˜ ë²¡í„°ë¡œ í‘œí˜„ë˜ëŠ” ì‚¬ìš©ì ë° í•­ëª©ì˜ ì ì¬ íŠ¹ì„±ì„ ëª¨ë¸ë§í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤.


Latent factor models have been very popular ever since their effectiveness was demonstrated for movie recommendation in the Netflix Prize [8].
ì ì¬ ìš”ì¸ ëª¨ë¸ì€ Netflix Prize [8]ì—ì„œ ì˜í™” ì¶”ì²œì— ëŒ€í•œ íš¨ê³¼ê°€ ì…ì¦ ëœ ì´í›„ë¡œ ë§¤ìš° ì¸ê¸°ê°€ ìˆìŠµë‹ˆë‹¤.


#### 1.3 The semantic gap in music
1.3 ìŒì•…ì˜ ì˜ë¯¸ ì  ì°¨ì´


Latent factor vectors form a compact description of the different facets of usersâ€™ tastes, and the corresponding characteristics of the items. 
ì ì¬ ì¸ì ë²¡í„°ëŠ” ì‚¬ìš©ì ì·¨í–¥ì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ê³¼ í•­ëª©ì˜ í•´ë‹¹ íŠ¹ì„±ì— ëŒ€í•œ ê°„ëµí•œ ì„¤ëª…ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

![T1](./image/T1.PNG)
To demonstrate this, we computed latent factors for a small set of usage data, and listed some artists whose songs have very positive and very negative values for each factor in Table 1. 
ì´ë¥¼ ì¦ëª…í•˜ê¸° ìœ„í•´ ì‘ì€ ì‚¬ìš© ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ì ì¬ ìš”ì¸ì„ ê³„ì‚°í•˜ê³  ë…¸ë˜ê°€ ê° ìš”ì¸ì— ëŒ€í•´ ë§¤ìš° ê¸ì •ì ì´ê³  ë§¤ìš° ë¶€ì •ì ì¸ ê°’ì„ ê°–ëŠ” ì¼ë¶€ ì•„í‹°ìŠ¤íŠ¸ë¥¼ í‘œ 1ì— ë‚˜ì—´í–ˆìŠµë‹ˆë‹¤.


This representation is quite versatile and can be used for other applications besides recommendation, as we will show later (see Section 5.1). 
ì´ í‘œí˜„ì€ ë§¤ìš° ë‹¤ì–‘í•˜ë©° ë‚˜ì¤‘ì— ì„¤ëª… í•  ê¶Œì¥ ì‚¬í•­ ì™¸ì— ë‹¤ë¥¸ ì‘ìš© í”„ë¡œê·¸ë¨ì—ë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì„¹ì…˜ 5.1 ì°¸ì¡°).


Since usage data is scarce for many songs, it is often impossible to reliably estimate these factor vectors. 
ë§ì€ ë…¸ë˜ì— ëŒ€í•œ ì‚¬ìš© ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ìš”ì¸ ë²¡í„°ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì¶”ì •í•˜ëŠ” ê²ƒì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.


Therefore it would be useful to be able to predict them from music audio content.
ë”°ë¼ì„œ ìŒì•… ì˜¤ë””ì˜¤ ì½˜í…ì¸ ì—ì„œ ì˜ˆì¸¡í•  ìˆ˜ ìˆìœ¼ë©´ ìœ ìš©í•©ë‹ˆë‹¤.


There is a large semantic gap between the characteristics of a song that affect user preference, and the corresponding audio signal. 
ì‚¬ìš©ì ì„ í˜¸ë„ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë…¸ë˜ì˜ íŠ¹ì„±ê³¼ í•´ë‹¹ ì˜¤ë””ì˜¤ ì‹ í˜¸ ì‚¬ì´ì—ëŠ” í° ì˜ë¯¸ ì  ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.


Extracting high-level properties such as genre, mood, instrumentation and lyrical themes from audio signals requires powerful models that are capable of capturing the complex hierarchical structure of music. 
ì˜¤ë””ì˜¤ ì‹ í˜¸ì—ì„œ ì¥ë¥´, ë¶„ìœ„ê¸°, ì•…ê¸° ë° ì„œì •ì  í…Œë§ˆì™€ ê°™ì€ ë†’ì€ ìˆ˜ì¤€ì˜ ì†ì„±ì„ ì¶”ì¶œí•˜ë ¤ë©´ ìŒì•…ì˜ ë³µì¡í•œ ê³„ì¸µ êµ¬ì¡°ë¥¼ ìº¡ì²˜ í•  ìˆ˜ìˆëŠ” ê°•ë ¥í•œ ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.


Additionally, some properties are impossible to obtain from audio signals alone, such as the popularity of the artist, their reputation and and their location. 
ë˜í•œ ì•„í‹°ìŠ¤íŠ¸ì˜ ì¸ê¸°, ëª…ì„± ë° ìœ„ì¹˜ì™€ ê°™ì€ ì¼ë¶€ ì†ì„±ì€ ì˜¤ë””ì˜¤ ì‹ í˜¸ë§Œìœ¼ë¡œëŠ” ì–»ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.


Researchers in the domain of music information retrieval (MIR) concern themselves with extracting these high-level properties from music. 
ìŒì•… ì •ë³´ ê²€ìƒ‰ (MIR) ë¶„ì•¼ì˜ ì—°êµ¬ìë“¤ì€ ìŒì•…ì—ì„œ ì´ëŸ¬í•œ ë†’ì€ ìˆ˜ì¤€ì˜ ì†ì„±ì„ ì¶”ì¶œí•˜ëŠ” ë° ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤.


They have grown to rely on a particular set of engineered audio features, such as mel-frequency cepstral coefficients (MFCCs), which are used as input to simple classifiers or regressors, such as SVMs and linear regression [9]. 
SVM ë° ì„ í˜• íšŒê·€ [9]ì™€ ê°™ì€ ë‹¨ìˆœ ë¶„ë¥˜ê¸° ë˜ëŠ” íšŒê·€ ìì— ëŒ€í•œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” MFCC (mel-frequency cepstral coefficients)ì™€ ê°™ì€ íŠ¹ì • ì—”ì§€ë‹ˆì–´ë§ ì˜¤ë””ì˜¤ ê¸°ëŠ¥ ì„¸íŠ¸ì— ì˜ì¡´í•˜ë„ë¡ ì„±ì¥í–ˆìŠµë‹ˆë‹¤.

Recently this traditional approach has been challenged by some authors who have applied deep neural networks to MIR problems [10, 11, 12].
ìµœê·¼ì— ì´ëŸ¬í•œ ì „í†µì ì¸ ì ‘ê·¼ ë°©ì‹ì€ ì‹¬ì¸µ ì‹ ê²½ë§ì„ MIR ë¬¸ì œì— ì ìš©í•œ ì¼ë¶€ ì €ìì— ì˜í•´ ë„ì „ì„ ë°›ì•˜ìŠµë‹ˆë‹¤ [10, 11, 12].


In this paper, we strive to bridge the semantic gap in music by training deep convolutional neural networks to predict latent factors from music audio. 
ì´ ë…¼ë¬¸ì—ì„œ ìš°ë¦¬ëŠ” ìŒì•… ì˜¤ë””ì˜¤ì˜ ì ì¬ ìš”ì¸ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì‹¬ì¸µ ì»¨ë³¼ ë£¨ì…˜ ì‹ ê²½ë§ì„ í›ˆë ¨ì‹œì¼œ ìŒì•…ì˜ ì˜ë¯¸ ì  ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê¸° ìœ„í•´ ë…¸ë ¥í•©ë‹ˆë‹¤.


We evaluate our approach on an industrialscale dataset with audio excerpts of over 380,000 songs, and compare it with a more conventional approach using a bag-of-words feature representation for each song. 
ìš°ë¦¬ëŠ” 38 ë§Œ ê³¡ ì´ìƒì˜ ì˜¤ë””ì˜¤ ë°œì·Œë¡œ ì‚°ì—… ê·œëª¨ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ì ‘ê·¼ ë°©ì‹ì„ í‰ê°€í•˜ê³  ê° ë…¸ë˜ì— ëŒ€í•œ ë‹¨ì–´ ëª¨ìŒ ê¸°ëŠ¥ í‘œí˜„ì„ ì‚¬ìš©í•˜ëŠ”ë³´ë‹¤ ì¼ë°˜ì ì¸ ì ‘ê·¼ ë°©ì‹ê³¼ ë¹„êµí•©ë‹ˆë‹¤.


We assess to what extent it is possible to extract characteristics that affect user preference directly from audio signals, and evaluate the predictions from our models in a music recommendation setting. 
ì˜¤ë””ì˜¤ ì‹ í˜¸ì—ì„œ ì§ì ‘ ì‚¬ìš©ì ì„ í˜¸ë„ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” íŠ¹ì„±ì„ ì¶”ì¶œ í•  ìˆ˜ìˆëŠ” ì •ë„ë¥¼ í‰ê°€í•˜ê³  ìŒì•… ì¶”ì²œ ì„¤ì •ì—ì„œ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í‰ê°€í•©ë‹ˆë‹¤.

---

### 2. The dataset 

The Million Song Dataset (MSD) [13] is a collection of metadata and precomputed audio features for one million contemporary songs. 
Million Song Dataset (MSD) [13]ì€ í˜„ì¬ ë°±ë§Œ ê³¡ì— ëŒ€í•œ ë©”íƒ€ ë°ì´í„° ë° ë¯¸ë¦¬ ê³„ì‚° ëœ ì˜¤ë””ì˜¤ ê¸°ëŠ¥ ëª¨ìŒì…ë‹ˆë‹¤.


Several other datasets linked to the MSD are also available, featuring lyrics, cover songs, tags and user listening data. 
ê°€ì‚¬, ë¦¬ë©”ì´í¬ ê³¡, íƒœê·¸ ë° ì‚¬ìš©ì ì²­ì·¨ ë°ì´í„°ë¥¼ íŠ¹ì§•ìœ¼ë¡œí•˜ëŠ” MSDì— ì—°ê²°ëœ ì—¬ëŸ¬ ë°ì´í„° ì„¸íŠ¸ë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


This makes the dataset suitable for a wide range of different music information retrieval tasks. 
ì´ë¡œ ì¸í•´ ë°ì´í„° ì„¸íŠ¸ëŠ” ë‹¤ì–‘í•œ ìŒì•… ì •ë³´ ê²€ìƒ‰ ì‘ì—…ì— ì í•©í•©ë‹ˆë‹¤.


Two linked datasets are of interest for our experiments:
ë‘ ê°œì˜ ì—°ê²°ëœ ë°ì´í„° ì„¸íŠ¸ê°€ ì‹¤í—˜ì— ìœ ìš©í•©ë‹ˆë‹¤.


â€¢ The Echo Nest Taste Profile Subset provides play counts for over 380,000 songs in the MSD, gathered from 1 million users. 

The dataset was used in the Million Song Dataset challenge [14] last year.
â€¢ Echo Nest Taste Profile Subsetì€ ë°±ë§Œ ëª…ì˜ ì‚¬ìš©ìê°€ ìˆ˜ì§‘ í•œ MSDì—ìˆëŠ” 38 ë§Œ ê³¡ ì´ìƒì˜ ë…¸ë˜ì— ëŒ€í•œ ì¬ìƒ íšŸìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ì´ ë°ì´í„° ì„¸íŠ¸ëŠ” ì‘ë…„ Million Song Dataset Challenge [14]ì—ì„œ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.


â€¢ The Last.fm dataset provides tags for over 500,000 songs.
â€¢ Last.fm ë°ì´í„° ì„¸íŠ¸ëŠ” 500,000 ê°œ ì´ìƒì˜ ë…¸ë˜ì— ëŒ€í•œ íƒœê·¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.


Traditionally, research in music information retrieval (MIR) on large-scale datasets was limited to industry, because large collections of music audio cannot be published easily due to licensing issues.
ì „í†µì ìœ¼ë¡œ ëŒ€ê·œëª¨ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ MIR (Music Information Retrieval) ì—°êµ¬ëŠ” ë¼ì´ì„ ìŠ¤ ë¬¸ì œë¡œ ì¸í•´ ëŒ€ê·œëª¨ ìŒì•… ì˜¤ë””ì˜¤ ì»¬ë ‰ì…˜ì„ ì‰½ê²Œ ê²Œì‹œ í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ì—…ê³„ë¡œ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤.


The authors of the MSD circumvented these issues by providing precomputed features instead of raw audio. 
MSD ì‘ì„±ìëŠ” ì›ì‹œ ì˜¤ë””ì˜¤ ëŒ€ì‹  ë¯¸ë¦¬ ê³„ì‚° ëœ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í”¼í–ˆìŠµë‹ˆë‹¤.


Unfortunately, the audio features provided with the MSD are of limited use, and the process by which they were obtained is not very well documented. 
ì•ˆíƒ€ê¹ê²Œë„ MSDì™€ í•¨ê»˜ ì œê³µë˜ëŠ” ì˜¤ë””ì˜¤ ê¸°ëŠ¥ì€ ì œí•œì ìœ¼ë¡œ ì‚¬ìš©ë˜ë©° ì´ëŸ¬í•œ ê¸°ëŠ¥ì„ ì–»ì€ í”„ë¡œì„¸ìŠ¤ëŠ” ì˜ ë¬¸ì„œí™”ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.


The feature set was extended by Rauber et al. [15], but the absence of raw audio data, or at least a mid-level representation, is still an issue.
ê¸°ëŠ¥ ì„¸íŠ¸ëŠ” Rauber et al. ê·¸ëŸ¬ë‚˜ ì›ì‹œ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì ì–´ë„ ì¤‘ê°„ ìˆ˜ì¤€ì˜ í‘œí˜„ì´ ì—¬ì „íˆ ë¬¸ì œì…ë‹ˆë‹¤.


However, we were able to attain 29 second audio clips for over 99% of the dataset from 7digital.com. 
ê·¸ëŸ¬ë‚˜ 7digital.comì—ì„œ ë°ì´í„° ì„¸íŠ¸ì˜ 99 % ì´ìƒì— ëŒ€í•´ 29 ì´ˆ ì˜¤ë””ì˜¤ í´ë¦½ì„ ì–»ì„ ìˆ˜ìˆì—ˆìŠµë‹ˆë‹¤.


Due to its size, the MSD allows for the music recommendation problem to be studied in a more realistic setting than was previously possible. 
í¬ê¸° ë•Œë¬¸ì— MSDëŠ” ì´ì „ì— ê°€ëŠ¥í–ˆë˜ ê²ƒë³´ë‹¤ ë” í˜„ì‹¤ì ì¸ í™˜ê²½ì—ì„œ ìŒì•… ì¶”ì²œ ë¬¸ì œë¥¼ ì—°êµ¬ í•  ìˆ˜ ìˆë„ë¡í•©ë‹ˆë‹¤.


It is also worth noting that the Taste Profile Subset is one of the largest collaborative filtering datasets that are publicly available today.
ë˜í•œ Taste Profile Subsetì´ ì˜¤ëŠ˜ë‚  ê³µê°œì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ê°€ì¥ í° í˜‘ì—… í•„í„°ë§ ë°ì´í„° ì„¸íŠ¸ ì¤‘ í•˜ë‚˜ë¼ëŠ” ì ë„ ì£¼ëª©í•  ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.

---

### 3. Weighted matrix factorization

The Taste Profile Subset contains play counts per song and per user, which is a form of implicit feedback. 
Taste Profile Subsetì—ëŠ” ì•”ì‹œ ì  í”¼ë“œë°±ì˜ í•œ í˜•íƒœ ì¸ ë…¸ë˜ ë° ì‚¬ìš©ì ë‹¹ ì¬ìƒ íšŸìˆ˜ê°€ í¬í•¨ë©ë‹ˆë‹¤.


We know how many times the users have listened to each of the songs in the dataset, but they have not explicitly rated them. 
ì‚¬ìš©ìê°€ ë°ì´í„° ì„¸íŠ¸ì˜ ê° ë…¸ë˜ë¥¼ ëª‡ ë²ˆì´ë‚˜ ë“¤ì—ˆëŠ”ì§€ ì•Œê³  ìˆì§€ë§Œ ëª…ì‹œ ì ìœ¼ë¡œ í‰ê°€í•˜ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤.


However, we can assume that users will probably listen to songs more often if they enjoy them. 
ê·¸ëŸ¬ë‚˜ ì‚¬ìš©ìê°€ ë…¸ë˜ë¥¼ ì¦ê¸°ë©´ ë” ìì£¼ ë“£ê²Œ ë  ê²ƒì´ë¼ê³  ê°€ì • í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


If a user has never listened to a song, this can have many causes:
ì‚¬ìš©ìê°€ ë…¸ë˜ë¥¼ í•œ ë²ˆë„ ë“£ì§€ ì•Šì€ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ì—¬ëŸ¬ ì›ì¸ì´ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


for example, they might not be aware of it, or they might expect not to enjoy it. 
ì˜ˆë¥¼ ë“¤ì–´, ê·¸ë“¤ì€ ê·¸ê²ƒì„ ì¸ì‹í•˜ì§€ ëª»í•˜ê±°ë‚˜ ê·¸ê²ƒì„ ì¦ê¸°ì§€ ì•Šì„ ê²ƒì´ë¼ê³  ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


This setting is not compatible with traditional matrix factorization algorithms, which are aimed at predicting ratings. 
ì´ ì„¤ì •ì€ ë“±ê¸‰ ì˜ˆì¸¡ì„ ëª©í‘œë¡œí•˜ëŠ” ê¸°ì¡´ì˜ í–‰ë ¬ ë¶„í•´ ì•Œê³ ë¦¬ì¦˜ê³¼ í˜¸í™˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.


We used the weighted matrix factorization (WMF) algorithm, proposed by Hu et al. [16], to learn latent factor representations of all users and items in the Taste Profile Subset. 
Hu ë“±ì´ ì œì•ˆí•œ WMF (Weighted Matrix Factorization) ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. [16], Taste Profile Subsetì—ì„œ ëª¨ë“  ì‚¬ìš©ì ë° í•­ëª©ì˜ ì ì¬ ìš”ì¸ í‘œí˜„ì„ í•™ìŠµí•©ë‹ˆë‹¤.


This is a modified matrix factorization algorithm aimed at implicit feedback datasets. 
ì´ê²ƒì€ ì•”ì‹œ ì  í”¼ë“œë°± ë°ì´í„° ì„¸íŠ¸ë¥¼ ëª©í‘œë¡œí•˜ëŠ” ìˆ˜ì • ëœ ë§¤íŠ¸ë¦­ìŠ¤ ë¶„í•´ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.


Let rui be the play count for user u and song i. 
ruië¥¼ ì‚¬ìš©ì uì™€ ë…¸ë˜ iì˜ ì¬ìƒ íšŸìˆ˜ë¡œ ì§€ì •í•©ë‹ˆë‹¤.


For each user-item pair, we define a preference variable pui and a confidence variable cui (I(x) is the indicator function, Î± and  are hyperparameters):
ê° ì‚¬ìš©ì í•­ëª© ìŒì— ëŒ€í•´ ì„ í˜¸ ë³€ìˆ˜ puiì™€ ì‹ ë¢° ë³€ìˆ˜ cuië¥¼ ì •ì˜í•©ë‹ˆë‹¤ (I (x)ëŠ” í‘œì‹œê¸° í•¨ìˆ˜, Î±ì´ê³  í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì„).

![(1+2)](./image/(1+2).PNG)
The preference variable indicates whether user u has ever listened to song i. 
í™˜ê²½ ì„¤ì • ë³€ìˆ˜ëŠ” ì‚¬ìš©ì uê°€ ë…¸ë˜ ië¥¼ë“¤ì€ ì ì´ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.


If it is 1, we will assume the user enjoys the song. 
1ì´ë©´ ì‚¬ìš©ìê°€ ë…¸ë˜ë¥¼ ì¦ê¸´ë‹¤ ê³  ê°€ì •í•©ë‹ˆë‹¤.


The confidence variable measures how certain we are about this particular preference. 
ì‹ ë¢° ë³€ìˆ˜ëŠ” ìš°ë¦¬ê°€ì´ íŠ¹ì • ì„ í˜¸ë„ì— ëŒ€í•´ ì–¼ë§ˆë‚˜ í™•ì‹ í•˜ëŠ”ì§€ ì¸¡ì •í•©ë‹ˆë‹¤.


It is a function of the play count, because songs with higher play counts are more likely to be preferred. 
ì¬ìƒ íšŸìˆ˜ê°€ ë§ì€ ë…¸ë˜ê°€ ì„ í˜¸ ë  ê°€ëŠ¥ì„±ì´ ë†’ê¸° ë•Œë¬¸ì— ì¬ìƒ íšŸìˆ˜ì˜ í•¨ìˆ˜ì…ë‹ˆë‹¤.


If the song has never been played, the confidence variable will have a low value, because this is the least informative case.
ë…¸ë˜ë¥¼ í•œ ë²ˆë„ ì¬ìƒ í•œ ì ì´ì—†ëŠ” ê²½ìš° ì •ë³´ê°€ ê°€ì¥ ì ì€ ê²½ìš°ì´ë¯€ë¡œ ì‹ ë¢°ë„ ë³€ìˆ˜ ê°’ì´ ë‚®ìŠµë‹ˆë‹¤.


The WMF objective function is given by:
WMF ëª©ì  í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì œê³µë©ë‹ˆë‹¤.
![(3)](./image/(3).PNG)

where Î» is a regularization parameter, xu is the latent factor vector for user u, and yi is the latent factor vector for song i. 
ì—¬ê¸°ì„œ Î»ëŠ” ì •ê·œí™” ë§¤ê°œ ë³€ìˆ˜, xuëŠ” ì‚¬ìš©ì uì— ëŒ€í•œ ì ì¬ ì¸ì ë²¡í„°, yiëŠ” ë…¸ë˜ iì— ëŒ€í•œ ì ì¬ ì¸ì ë²¡í„°ì…ë‹ˆë‹¤.


It consists of a confidence-weighted mean squared error term and an L2 regularization term. 
ì‹ ë¢° ê°€ì¤‘ í‰ê·  ì œê³± ì˜¤ì°¨ í•­ê³¼ L2 ì •ê·œí™” í•­ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.


Note that the first sum ranges over all users and all songs: contrary to matrix factorization for rating prediction, where terms corresponding to user-item combinations for which no rating is available can be discarded, we have to take all possible combinations into account. 
ì²« ë²ˆì§¸ í•©ê³„ëŠ” ëª¨ë“  ì‚¬ìš©ìì™€ ëª¨ë“  ë…¸ë˜ì— ì ìš©ë©ë‹ˆë‹¤. ë“±ê¸‰ ì˜ˆì¸¡ì„ìœ„í•œ í–‰ë ¬ ë¶„í•´ì™€ ë‹¬ë¦¬ ë“±ê¸‰ì´ì—†ëŠ” ì‚¬ìš©ì í•­ëª© ì¡°í•©ì— í•´ë‹¹í•˜ëŠ” ìš©ì–´ë¥¼ ë²„ë¦´ ìˆ˜ìˆëŠ” ê²½ìš° ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•©ì„ ê³ ë ¤í•´ì•¼í•©ë‹ˆë‹¤.


As a result, using stochastic gradient descent for optimization is not practical for a dataset of this size. 
ê²°ê³¼ì ìœ¼ë¡œ ìµœì í™”ë¥¼ ìœ„í•´ í™•ë¥  ì  ê²½ì‚¬ í•˜ê°• ë²•ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ì´ í¬ê¸°ì˜ ë°ì´í„° ì„¸íŠ¸ì— ì‹¤ìš©ì ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.


Hu et al. propose an efficient alternating least squares (ALS) optimization method, which we used instead.
Hu et al. ëŒ€ì‹  ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ êµë²ˆ ìµœì†Œ ì œê³± (ALS) ìµœì í™” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.

---

### 4. Predicting latent factors from music audio 

Predicting latent factors for a given song from the corresponding audio signal is a regression problem. 
í•´ë‹¹ ì˜¤ë””ì˜¤ ì‹ í˜¸ì—ì„œ ì£¼ì–´ì§„ ë…¸ë˜ì˜ ì ì¬ ìš”ì¸ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì€ íšŒê·€ ë¬¸ì œì…ë‹ˆë‹¤.


It requires learning a function that maps a time series to a vector of real numbers. 
ì‹œê³„ì—´ì„ ì‹¤ìˆ˜ ë²¡í„°ì— ë§¤í•‘í•˜ëŠ” í•¨ìˆ˜ë¥¼ í•™ìŠµí•´ì•¼í•©ë‹ˆë‹¤.


We evaluate two methods to achieve this: one follows the conventional approach in MIR by extracting local features from audio signals and aggregating them into a bag-of-words (BoW) representation. 
ì´ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ë°©ë²•ì„ í‰ê°€í•©ë‹ˆë‹¤. í•˜ë‚˜ëŠ” ì˜¤ë””ì˜¤ ì‹ í˜¸ì—ì„œ ë¡œì»¬ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³ ì´ë¥¼ BoW (bag-of-words) í‘œí˜„ìœ¼ë¡œ ì§‘ê³„í•˜ì—¬ MIRì˜ ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì„ ë”°ë¦…ë‹ˆë‹¤.


Any traditional regression technique can then be used to map this feature representation to the factors. 
ê·¸ëŸ° ë‹¤ìŒ ê¸°ì¡´ íšŒê·€ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ì´ íŠ¹ì§• í‘œí˜„ì„ ìš”ì¸ì— ë§¤í•‘ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


The other method is to use a deep convolutional network. 
ë‹¤ë¥¸ ë°©ë²•ì€ ì‹¬ì¸µ ì»¨ë³¼ ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.


Latent factor vectors obtained by applying WMF to the available usage data are used as ground truth to train the prediction models. 
ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ìš© ë°ì´í„°ì— WMFë¥¼ ì ìš©í•˜ì—¬ ì–»ì€ ì ì¬ ì¸ì ë²¡í„°ëŠ” ì˜ˆì¸¡ ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸°ìœ„í•œ ì§€ìƒ ì§„ì‹¤ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.


It should be noted that this approach is compatible with any type of latent factor model that is suitable for large implicit feedback datasets. 
ì´ ì ‘ê·¼ ë°©ì‹ì€ ëŒ€ê·œëª¨ ì•”ì‹œ ì  í”¼ë“œë°± ë°ì´í„° ì„¸íŠ¸ì— ì í•©í•œ ëª¨ë“  ìœ í˜•ì˜ ì ì¬ ìš”ì¸ ëª¨ë¸ê³¼ í˜¸í™˜ëœë‹¤ëŠ” ì ì— ìœ ì˜í•´ì•¼í•©ë‹ˆë‹¤.


We chose to use WMF because an efficient optimization procedure exists for it.
íš¨ìœ¨ì ì¸ ìµœì í™” ì ˆì°¨ê°€ ìˆê¸° ë•Œë¬¸ì— WMFë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ì„ íƒí–ˆìŠµë‹ˆë‹¤.

#### 4.1 Bag-of-words representation

Many MIR systems rely on the following feature extraction pipeline to convert music audio signals into a fixed-size representation that can be used as input to a classifier or regressor [5, 17, 18, 19, 20]:
ë§ì€ MIR ì‹œìŠ¤í…œì€ ìŒì•… ì˜¤ë””ì˜¤ ì‹ í˜¸ë¥¼ ë¶„ë¥˜ê¸° ë˜ëŠ” íšŒê·€ ìì— ëŒ€í•œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ìˆëŠ” ê³ ì • í¬ê¸° í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ê¸°ëŠ¥ ì¶”ì¶œ íŒŒì´í”„ ë¼ì¸ì— ì˜ì¡´í•©ë‹ˆë‹¤ [5, 17, 18, 19, 20].


â€¢ Extract MFCCs from the audio signals. 
â€¢ ì˜¤ë””ì˜¤ ì‹ í˜¸ì—ì„œ MFCCë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.


We computed 13 MFCCs from windows of 1024 audio frames, corresponding to 23 ms at a sampling rate of 22050 Hz, and a hop size of 512 samples. 
ìš°ë¦¬ëŠ” 1024 ì˜¤ë””ì˜¤ í”„ë ˆì„ì˜ ì°½ì—ì„œ 13 ê°œì˜ MFCCë¥¼ ê³„ì‚°í–ˆëŠ”ë°, ì´ëŠ” 22050Hzì˜ ìƒ˜í”Œë§ ì†ë„ì™€ 512 ê°œ ìƒ˜í”Œì˜ í™‰ í¬ê¸°ì—ì„œ 23msì— í•´ë‹¹í•©ë‹ˆë‹¤.


We also computed first and second order differences, yielding 39 coefficients in total.
ë˜í•œ 1 ì°¨ì™€ 2 ì°¨ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ì—¬ ì´ 39 ê°œì˜ ê³„ìˆ˜ë¥¼ ì‚°ì¶œí–ˆìŠµë‹ˆë‹¤.


â€¢ Vector quantize the MFCCs. 
â€¢ ë²¡í„°ëŠ” MFCCë¥¼ ì–‘ìí™”í•©ë‹ˆë‹¤.


We learned a dictionary of 4000 elements with the K-means algorithm and assigned all MFCC vectors to the closest mean.
K- í‰ê·  ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ 4000 ê°œ ìš”ì†Œ ì‚¬ì „ì„ í•™ìŠµí•˜ê³  ëª¨ë“  MFCC ë²¡í„°ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ í‰ê· ì— í• ë‹¹í–ˆìŠµë‹ˆë‹¤.


â€¢ Aggregate them into a bag-of-words representation. 
â€¢ ë‹¨ì–´ ëª¨ìŒ í‘œí˜„ìœ¼ë¡œ ì§‘ê³„í•©ë‹ˆë‹¤.


For every song, we counted how many times each mean was selected. 
ëª¨ë“  ë…¸ë˜ì— ëŒ€í•´ ê° í‰ê· ì´ ì„ íƒëœ íšŸìˆ˜ë¥¼ ì„¸ì—ˆìŠµë‹ˆë‹¤.


The resulting vector of counts is a bag-of-words feature representation of the song.
ê²°ê³¼ì ì¸ ì¹´ìš´íŠ¸ ë²¡í„°ëŠ” ë…¸ë˜ì˜ ë‹¨ì–´ ëª¨ìŒ ê¸°ëŠ¥ í‘œí˜„ì…ë‹ˆë‹¤.


We then reduced the size of this representation using PCA (we kept enough components to retain 95% of the variance) and used linear regression and a multilayer perceptron with 1000 hidden units on top of this to predict latent factors. 
ê·¸ëŸ° ë‹¤ìŒ PCAë¥¼ ì‚¬ìš©í•˜ì—¬ì´ í‘œí˜„ì˜ í¬ê¸°ë¥¼ ì¤„ì´ê³  (ë¶„ì‚°ì˜ 95 %ë¥¼ ìœ ì§€í•˜ê¸°ì— ì¶©ë¶„í•œ êµ¬ì„± ìš”ì†Œë¥¼ ìœ ì§€í•¨) ì„ í˜• íšŒê·€ì™€ 1000 ê°œì˜ ì€ë‹‰ ìœ ë‹›ì´ìˆëŠ” ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ ì„ ì‚¬ìš©í•˜ì—¬ ì ì¬ ìš”ì¸ì„ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.


We also used it as input for the metric learning to rank (MLR) algorithm [21], to learn a similarity metric for content-based recommendation. 
ë˜í•œ MLR (metric learning to rank) ì•Œê³ ë¦¬ì¦˜ [21]ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œì— ëŒ€í•œ ìœ ì‚¬ì„± ë©”íŠ¸ë¦­ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.


This was used as a baseline for our music recommendation experiments, which are described in Section 5.2.
ì´ëŠ” ì„¹ì…˜ 5.2ì— ì„¤ëª… ëœ ìŒì•… ì¶”ì²œ ì‹¤í—˜ì˜ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.

#### 4.2 Convolutional neural networks

Convolutional neural networks (CNNs) have recently been used to improve on the state of the art in speech recognition and large-scale image classification by a large margin [22, 23]. 
ì»¨ë³¼ ë£¨ì…˜ ì‹ ê²½ë§ (CNN)ì€ ìµœê·¼ ìŒì„± ì¸ì‹ ë° ëŒ€ê·œëª¨ ì´ë¯¸ì§€ ë¶„ë¥˜ì˜ ìµœì²¨ë‹¨ ê¸°ìˆ ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” ë° ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤ [22, 23].


Three ingredients seem to be central to the success of this approach:
ì´ ì ‘ê·¼ ë°©ì‹ì˜ ì„±ê³µì—ëŠ” ì„¸ ê°€ì§€ ìš”ì†Œê°€ í•µì‹¬ì ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.


â€¢ Using rectified linear units (ReLUs) [24] instead of sigmoid nonlinearities leads to faster convergence and reduces the vanishing gradient problem that plagues traditional neural networks with many layers.
â€¢ Parallellization is used to speed up training, so that larger models can be trained in a reasonable amount of time. 
â€¢ ì‹œê·¸ ëª¨ì´ ë“œ ë¹„ì„ í˜• ì„± ëŒ€ì‹  ReLU (rectified linear unit) [24]ë¥¼ ì‚¬ìš©í•˜ë©´ ìˆ˜ë ´ ì†ë„ê°€ ë¹¨ë¼ì§€ê³  ë ˆì´ì–´ê°€ ë§ì€ ê¸°ì¡´ ì‹ ê²½ë§ì„ ê´´ë¡­íˆëŠ” ì†Œì‹¤ ê¸°ìš¸ê¸° ë¬¸ì œê°€ ì¤„ì–´ ë“­ë‹ˆë‹¤.
â€¢ ë³‘ë ¬í™”ëŠ” í›ˆë ¨ ì†ë„ë¥¼ ë†’ì´ëŠ” ë° ì‚¬ìš©ë˜ë¯€ë¡œ ë” í° ëª¨ë¸ì„ ì ì ˆí•œ ì‹œê°„ì— í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


We used the Theano library [25] to take advantage of GPU acceleration.
GPU ê°€ì†ì„ í™œìš©í•˜ê¸° ìœ„í•´ Theano ë¼ì´ë¸ŒëŸ¬ë¦¬ [25]ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.


â€¢ A large amount of training data is required to be able to fit large models with many parameters. 
â€¢ ë§¤ê°œ ë³€ìˆ˜ê°€ ë§ì€ ëŒ€í˜• ëª¨ë¸ì— ì í•©í•˜ë ¤ë©´ ë§ì€ ì–‘ì˜ í›ˆë ¨ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.


The MSD contains enough training data to be able to train large models effectively. 
MSDì—ëŠ” ëŒ€ê·œëª¨ ëª¨ë¸ì„ íš¨ê³¼ì ìœ¼ë¡œ í›ˆë ¨ í•  ìˆ˜ìˆëŠ” ì¶©ë¶„í•œ í›ˆë ¨ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.


We have also evaluated the use of dropout regularization [26], but this did not yield any significant improvements.
ë˜í•œ dropout regularization [26]ì˜ ì‚¬ìš©ì„ í‰ê°€í–ˆì§€ë§Œ ì´ë¡œ ì¸í•´ í° ê°œì„ ì´ ì´ë£¨ì–´ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.


We first extracted an intermediate time-frequency representation from the audio signals to use as input to the network. 
ë¨¼ì € ì˜¤ë””ì˜¤ ì‹ í˜¸ì—ì„œ ì¤‘ê°„ ì‹œê°„-ì£¼íŒŒìˆ˜ í‘œí˜„ì„ ì¶”ì¶œí•˜ì—¬ ë„¤íŠ¸ì›Œí¬ì— ëŒ€í•œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.


We used log-compressed mel-spectrograms with 128 components and the same window size and hop size that we used for the MFCCs (1024 and 512 audio frames respectively).
128 ê°œì˜ êµ¬ì„± ìš”ì†Œì™€ MFCC (ê°ê° 1024 ë° 512 ì˜¤ë””ì˜¤ í”„ë ˆì„)ì— ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•œ ì°½ í¬ê¸° ë° í™‰ í¬ê¸°ê°€ìˆëŠ” ë¡œê·¸ ì••ì¶• ëœ ë©œ-ìŠ¤í™íŠ¸ë¡œ ê·¸ë¨ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.


The networks were trained on windows of 3 seconds sampled randomly from the audio clips. 
ë„¤íŠ¸ì›Œí¬ëŠ” ì˜¤ë””ì˜¤ í´ë¦½ì—ì„œ ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§ ëœ 3 ì´ˆì˜ ì°½ì—ì„œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤.


This was done primarily to speed up training. 
ì´ê²ƒì€ ì£¼ë¡œ í›ˆë ¨ ì†ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.


To predict the latent factors for an entire clip, we averaged over the predictions for consecutive windows.
ì „ì²´ í´ë¦½ì˜ ì ì¬ ìš”ì¸ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì—°ì† ì°½ì— ëŒ€í•œ ì˜ˆì¸¡ì„ í‰ê· í–ˆìŠµë‹ˆë‹¤.


Convolutional neural networks are especially suited for predicting latent factors from music audio, because they allow for intermediate features to be shared between different factors, and because their hierarchical structure consisting of alternating feature extraction layers and pooling layers allows them to operate on multiple timescales.
ì»¨ë³¼ ë£¨ì…˜ ì‹ ê²½ë§ì€ ìŒì•… ì˜¤ë””ì˜¤ì˜ ì ì¬ ìš”ì¸ì„ ì˜ˆì¸¡í•˜ëŠ” ë° íŠ¹íˆ ì í•©í•©ë‹ˆë‹¤. ì™œëƒí•˜ë©´ ì¤‘ê°„ ê¸°ëŠ¥ì„ ì„œë¡œ ë‹¤ë¥¸ ìš”ì¸ê°„ì— ê³µìœ  í•  ìˆ˜ ìˆê³  ê¸°ëŠ¥ ì¶”ì¶œ ë ˆì´ì–´ì™€ í’€ë§ ë ˆì´ì–´ë¥¼ ë²ˆê°ˆì•„ ì‚¬ìš©í•˜ëŠ” ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ì—¬ëŸ¬ ì‹œê°„ ì²™ë„ì—ì„œ ì‘ë™ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

#### 4.3 Objective functions 

Latent factor vectors are real-valued, so the most straightforward objective is to minimize the mean squared error (MSE) of the predictions. 
ì ì¬ ì¸ì ë²¡í„°ëŠ” ì‹¤ìˆ˜ ê°’ì´ë¯€ë¡œ ê°€ì¥ ê°„ë‹¨í•œ ëª©í‘œëŠ” ì˜ˆì¸¡ì˜ í‰ê·  ì œê³± ì˜¤ì°¨ (MSE)ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.


Alternatively, we can also continue to minimize the weighted prediction error (WPE) from the WMF objective function. 
ë˜ëŠ” WMF ëª©ì  í•¨ìˆ˜ì—ì„œ WPE (ê°€ì¤‘ ì˜ˆì¸¡ ì˜¤ì°¨)ë¥¼ ê³„ì† ìµœì†Œí™” í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.


Let yi be the latent factor vector for song i, obtained with WMF, and y0i the corresponding prediction by the model. 
yië¥¼ WMFë¡œ ì–»ì€ ë…¸ë˜ iì— ëŒ€í•œ ì ì¬ ì¸ì ë²¡í„°ì´ê³  y0ië¥¼ ëª¨ë¸ì— ì˜í•œ í•´ë‹¹ ì˜ˆì¸¡ì´ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.


The objective functions are then (Î¸ represents the model parameters):
![(5)](./image/(5).PNG)
ëª©ì  í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ (Î¸ëŠ” ëª¨ë¸ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ„).

---

### 5. Experiments
#### 5.1 Versatility of the latent factor representation

To demonstrate the versatility of the latent factor vectors, we compared them with audio features in a tag prediction task. 
ì ì¬ ì¸ì ë²¡í„°ì˜ ë‹¤ì–‘ì„±ì„ ì…ì¦í•˜ê¸° ìœ„í•´ íƒœê·¸ ì˜ˆì¸¡ ì‘ì—…ì˜ ì˜¤ë””ì˜¤ ê¸°ëŠ¥ê³¼ ë¹„êµí–ˆìŠµë‹ˆë‹¤.


Tags can describe a wide range of different aspects of the songs, such as genre, instrumentation, tempo, mood and year of release.
íƒœê·¸ëŠ” ì¥ë¥´, ì•…ê¸°, í…œí¬, ë¶„ìœ„ê¸° ë° ì¶œì‹œ ì—°ë„ì™€ ê°™ì€ ë…¸ë˜ì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì„ ì„¤ëª… í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


We ran WMF to obtain 50-dimensional latent factor vectors for all 9,330 songs in the subset, and trained a logistic regression model to predict the 50 most popular tags from the Last.fm dataset for each song. 
WMFë¥¼ ì‹¤í–‰í•˜ì—¬ í•˜ìœ„ ì§‘í•©ì˜ ëª¨ë“  9,330 ê³¡ì— ëŒ€í•œ 50 ì°¨ì› ì ì¬ ì¸ì ë²¡í„°ë¥¼ ì–»ê³  ê° ë…¸ë˜ì˜ Last.fm ë°ì´í„° ì„¸íŠ¸ì—ì„œ ê°€ì¥ ì¸ê¸°ìˆëŠ” 50 ê°œì˜ íƒœê·¸ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ í›ˆë ¨í–ˆìŠµë‹ˆë‹¤.


We also trained a logistic regression model on a bag-of-words representation of the audio signals, which was first reduced in size using PCA (see Section 4.1). 
ìš°ë¦¬ëŠ” ë˜í•œ ì˜¤ë””ì˜¤ ì‹ í˜¸ì˜ bag-of-words í‘œí˜„ì— ëŒ€í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ í›ˆë ¨ ì‹œì¼°ëŠ”ë°, ì´ëŠ” PCAë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ìŒ í¬ê¸°ê°€ ì¶•ì†Œë˜ì—ˆìŠµë‹ˆë‹¤ (ì„¹ì…˜ 4.1 ì°¸ì¡°).


We used 10-fold crossvalidation and computed the average area under the ROC curve (AUC) across all tags. 
10 ê²¹ êµì°¨ ê²€ì¦ì„ ì‚¬ìš©í•˜ê³  ëª¨ë“  íƒœê·¸ì—ì„œ ROC ê³¡ì„  ì•„ë˜ì˜ í‰ê·  ë©´ì  (AUC)ì„ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤.


This resulted in an average AUC of 0.69365 for audio-based prediction, and 0.86703 for prediction based on the latent factor vectors.
ê·¸ ê²°ê³¼ ì˜¤ë””ì˜¤ ê¸°ë°˜ ì˜ˆì¸¡ì˜ ê²½ìš° í‰ê·  AUCê°€ 0.69365ì´ê³  ì ì¬ ì¸ì ë²¡í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì˜ˆì¸¡ì˜ ê²½ìš° 0.86703ì´ë˜ì—ˆìŠµë‹ˆë‹¤.

#### 5.2 Latent factor prediction: quantitative evaluation
5.2 ì ì¬ ì¸ì ì˜ˆì¸¡ : ì •ëŸ‰ì  í‰ê°€

To assess quantitatively how well we can predict latent factors from music audio, we used the predictions from our models for music recommendation. 
ìŒì•… ì˜¤ë””ì˜¤ì˜ ì ì¬ ìš”ì¸ì„ ì–¼ë§ˆë‚˜ ì˜ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ”ì§€ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•˜ê¸° ìœ„í•´ ìŒì•… ì¶”ì²œì„ ìœ„í•´ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.


For every user u and for every song i in the test set, we computed the score xTuyi, and recommended the songs with the highest scores first. 
ëª¨ë“  ì‚¬ìš©ì uì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ëª¨ë“  ë…¸ë˜ iì— ëŒ€í•´ ì ìˆ˜ xTuyië¥¼ ê³„ì‚°í•˜ê³  ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ë…¸ë˜ë¥¼ ë¨¼ì € ì¶”ì²œí–ˆìŠµë‹ˆë‹¤.


Asmentioned before, we also learned a song similarity metric on the bag-of-words representation using metric learning to rank. 
ì•ì„œ ì–¸ê¸‰í–ˆë“¯ì´ ìš°ë¦¬ëŠ” ìˆœìœ„ë¥¼ ë§¤ê¸°ê¸° ìœ„í•´ ë©”íŠ¸ë¦­ í•™ìŠµì„ ì‚¬ìš©í•˜ì—¬ bag-of-words í‘œí˜„ì— ëŒ€í•œ ë…¸ë˜ ìœ ì‚¬ì„± ë©”íŠ¸ë¦­ë„ ë°°ì› ìŠµë‹ˆë‹¤.


In this case, scores for a given user are computed by averaging similarity scores across all the songs that the user has listened to.
ì´ ê²½ìš° íŠ¹ì • ì‚¬ìš©ìì˜ ì ìˆ˜ëŠ” ì‚¬ìš©ìê°€ë“¤ì€ ëª¨ë“  ë…¸ë˜ì˜ ìœ ì‚¬ì„± ì ìˆ˜ë¥¼ í‰ê· í•˜ì—¬ ê³„ì‚°ë©ë‹ˆë‹¤.


The following models were used to predict latent factor vectors:
ì ì¬ ì¸ì ë²¡í„°ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ëª¨ë¸ì´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.


â€¢ Linear regression trained on the bag-of-words representation described in Section 4.1.
â€¢ A multi-layer perceptron (MLP) trained on the same bag-of-words representation.
â€¢ A convolutional neural network trained on log-scaled mel-spectrograms to minimize the mean squared error (MSE) of the predictions.
â€¢ The same convolutional neural network, trained to minimize the weighted prediction error(WPE) from the WMF objective instead.
â€¢ ì„¹ì…˜ 4.1ì— ì„¤ëª… ëœ bag-of-words í‘œí˜„ì— ëŒ€í•´ í›ˆë ¨ ëœ ì„ í˜• íšŒê·€.
â€¢ ë™ì¼í•œ bag-of-words í‘œí˜„ì— ëŒ€í•´ í›ˆë ¨ ëœ ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  (MLP).
â€¢ ì˜ˆì¸¡ì˜ í‰ê·  ì œê³± ì˜¤ì°¨ (MSE)ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ë¡œê·¸ ìŠ¤ì¼€ì¼ ëœ ë©œ-ìŠ¤í™íŠ¸ë¡œ ê·¸ë¨ì—ì„œ í›ˆë ¨ ëœ ì»¨ë²Œë£¨ì…˜ ì‹ ê²½ë§.
â€¢ ëŒ€ì‹  WMF ëª©í‘œì—ì„œ ê°€ì¤‘ ì˜ˆì¸¡ ì˜¤ì°¨ (WPE)ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ í›ˆë ¨ ëœ ë™ì¼í•œ ì»¨ë²Œë£¨ì…˜ ì‹ ê²½ë§.


For our initial experiments, we used a subset of the dataset containing only the 9,330 most popular songs, and listening data for only 20,000 users. 
ì´ˆê¸° ì‹¤í—˜ì—ì„œëŠ” 9,330 ê°œì˜ ê°€ì¥ ì¸ê¸°ìˆëŠ” ë…¸ë˜ì™€ 20,000 ëª…ì˜ ì‚¬ìš©ìì— ëŒ€í•œ ì²­ì·¨ ë°ì´í„° ë§Œ í¬í•¨ ëœ ë°ì´í„° ì„¸íŠ¸ì˜ í•˜ìœ„ ì§‘í•©ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.


We used 1,881 songs for testing. 
í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 1,881 ê³¡ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.


For the other experiments, we used all available data: we used all songs that we have usage data for and that we were able to download an audio clip for (382,410 songs and 1 million users in total, 46,728 songs were used for testing).
ë‹¤ë¥¸ ì‹¤í—˜ì—ì„œëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì‚¬ìš© ë°ì´í„°ê°€ ìˆê³  ì˜¤ë””ì˜¤ í´ë¦½ì„ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ìˆëŠ” ëª¨ë“  ë…¸ë˜ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤ (382,410 ê³¡, ì´ ì‚¬ìš©ì 100 ë§Œ ëª…, í…ŒìŠ¤íŠ¸ì— 46,728 ê³¡ ì‚¬ìš©).


We report the mean average precision (mAP, cut off at 500 recommendations per user) and the area under the ROC curve (AUC) of the predictions. 
í‰ê·  í‰ê·  ì •ë°€ë„ (mAP, ì‚¬ìš©ì ë‹¹ ê¶Œì¥ ì‚¬í•­ 500 ê°œì—ì„œ ì˜ë¦¼)ì™€ ì˜ˆì¸¡ì˜ ROC ê³¡ì„  ì•„ë˜ ì˜ì—­ (AUC)ì„ë³´ê³ í•©ë‹ˆë‹¤.


We evaluated all models on the subset, using latent factor vectors with 50 dimensions. 
50 ê°œ ì°¨ì›ì˜ ì ì¬ ì¸ì ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶€ë¶„ ì§‘í•©ì˜ ëª¨ë“  ëª¨ë¸ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.


We compared the convolutional neural network with linear regression on the bag-of-words representation on the full dataset as well, using latent factor vectors with 400 dimensions. 
ì»¨ë²Œë£¨ì…˜ ì‹ ê²½ë§ê³¼ ì „ì²´ ë°ì´í„° ì„¸íŠ¸ì˜ ë‹¨ì–´ ëª¨ìŒ í‘œí˜„ì— ëŒ€í•œ ì„ í˜• íšŒê·€ë¥¼ 400 ì°¨ì›ì˜ ì ì¬ ì¸ì ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„êµí–ˆìŠµë‹ˆë‹¤.

![T2](./image/T2.PNG)
Results are shown in Tables 2 and 3 respectively.
ê²°ê³¼ëŠ” ê°ê° í‘œ 2 ë° 3ì— ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤.


On the subset, predicting the latent factors seems to outperform the metric learning approach. 
í•˜ìœ„ ì§‘í•©ì—ì„œ ì ì¬ ìš”ì¸ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì€ ë©”íŠ¸ë¦­ í•™ìŠµ ì ‘ê·¼ ë°©ì‹ì„ ëŠ¥ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.

Using an MLP instead of linear regression results in a slight improvement, but the limitation here is clearly the bag-of-words feature representation. 
ì„ í˜• íšŒê·€ ëŒ€ì‹  MLPë¥¼ ì‚¬ìš©í•˜ë©´ ì•½ê°„ì˜ ê°œì„ ì´ ì´ë£¨ì–´ ì§€ì§€ë§Œ ì—¬ê¸°ì„œ í•œê³„ëŠ” ë¶„ëª…íˆ bag-of-words ê¸°ëŠ¥ í‘œí˜„ì…ë‹ˆë‹¤.


Using a convolutional neural network results in another large increase in performance. 
ì»¨ë³¼ ë£¨ì…˜ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.


Most likely this is because the bag-of-words representation does not reflect any kind of temporal structure.
ì•„ë§ˆë„ ì´ê²ƒì€ bag-of-words í‘œí˜„ì´ ì–´ë–¤ ì¢…ë¥˜ì˜ ì‹œê°„ì  êµ¬ì¡°ë„ ë°˜ì˜í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.


Interestingly, the WPE objective does not result in improved performance. 
í¥ë¯¸ë¡­ê²Œë„ WPE ëª©í‘œëŠ” ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤.


Presumably this is because the weighting causes the importance of the songs to be proportional to their popularity. 
ì•„ë§ˆë„ ì´ê²ƒì€ ê°€ì¤‘ì¹˜ë¡œ ì¸í•´ ë…¸ë˜ì˜ ì¤‘ìš”ì„±ì´ ì¸ê¸°ì— ë¹„ë¡€í•˜ê¸° ë•Œë¬¸ì¼ ê²ƒì…ë‹ˆë‹¤.


In other words, the model will be encouraged to predict latent factor vectors for popular songs from the training set very well, at the expense of all other songs.
ì¦‰, ëª¨ë¸ì€ ë‹¤ë¥¸ ëª¨ë“  ë…¸ë˜ë¥¼ í¬ìƒì‹œí‚¤ë©´ì„œ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ì¸ê¸°ìˆëŠ” ë…¸ë˜ì— ëŒ€í•œ ì ì¬ ì¸ì ë²¡í„°ë¥¼ ë§¤ìš° ì˜ ì˜ˆì¸¡í•˜ë„ë¡ ê¶Œì¥ë©ë‹ˆë‹¤.


On the full dataset, the difference between the bag-ofwords approach and the convolutional neural network is much more pronounced. 
ì „ì²´ ë°ì´í„° ì„¸íŠ¸ì—ì„œ bag-ofwords ì ‘ê·¼ ë°©ì‹ê³¼ ì»¨ë³¼ ë£¨ì…˜ ì‹ ê²½ë§ ê°„ì˜ ì°¨ì´ê°€ í›¨ì”¬ ë” ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤.


Note that we did not train an MLP on this dataset due to the small difference in performance with linear regression on the subset. 
í•˜ìœ„ ì§‘í•©ì— ëŒ€í•œ ì„ í˜• íšŒê·€ì™€ì˜ ì„±ëŠ¥ ì°¨ì´ê°€ ì‘ê¸° ë•Œë¬¸ì—ì´ ë°ì´í„° ì„¸íŠ¸ì—ì„œ MLPë¥¼ í›ˆë ¨í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.


We also included results for when the latent factor vectors are obtained from usage data. 
ë˜í•œ ì‚¬ìš© ë°ì´í„°ì—ì„œ ì ì¬ ì¸ì ë²¡í„°ë¥¼ ì–»ì€ ê²½ìš°ì— ëŒ€í•œ ê²°ê³¼ë„ í¬í•¨í–ˆìŠµë‹ˆë‹¤.


This is an upper bound to what is achievable when predicting them from content. 
ì´ëŠ” ì½˜í…ì¸ ì—ì„œ ì˜ˆì¸¡í•  ë•Œ ë‹¬ì„± í•  ìˆ˜ìˆëŠ” ê²ƒì˜ ìƒí•œì„ ì…ë‹ˆë‹¤.
![T3](./image/T3.PNG)

There is a large gap between our best result and this theoretical maximum, but this is to be expected: as we mentioned before, many aspects of the songs that influence user preference cannot possibly be extracted from audio signals only. 
ìµœìƒì˜ ê²°ê³¼ì™€ ì´ë¡ ì  ìµœëŒ€ ê°’ ì‚¬ì´ì—ëŠ” í° ì°¨ì´ê°€ ìˆì§€ë§Œ ì´ëŠ” ì˜ˆìƒ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•ì—ì„œ ì–¸ê¸‰í–ˆë“¯ì´ ì‚¬ìš©ì ì„ í˜¸ë„ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë…¸ë˜ì˜ ë§ì€ ì¸¡ë©´ì€ ì˜¤ë””ì˜¤ ì‹ í˜¸ì—ì„œë§Œ ì¶”ì¶œ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.


In particular, we are unable to predict the popularity of the songs, which considerably affects the AUC and mAP scores.
íŠ¹íˆ AUC ë° mAP ì ìˆ˜ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê³¡ì˜ ì¸ê¸°ë„ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.


#### 5.3 Latent factor prediction: qualitative evaluation
5.3 ì ì¬ ì¸ì ì˜ˆì¸¡ : ì • ì„±ì  í‰ê°€


Evaluating recommender systems is a complex matter, and accuracy metrics by themselves do not provide enough insight into whether the recommendations are sound. 
ì¶”ì²œ ì‹œìŠ¤í…œì„ í‰ê°€í•˜ëŠ” ê²ƒì€ ë³µì¡í•œ ë¬¸ì œì´ë©° ì •í™•ë„ ë©”íŠ¸ë¦­ ìì²´ë§Œìœ¼ë¡œëŠ” ì¶”ì²œì´ ì˜¬ë°”ë¥¸ì§€ì— ëŒ€í•œ ì¶©ë¶„í•œ í†µì°°ë ¥ì„ ì œê³µí•˜ì§€ ëª»í•©ë‹ˆë‹¤.


To establish this, we also performed some qualitative experiments on the subset. 
ì´ë¥¼ ì„¤ì •í•˜ê¸° ìœ„í•´ í•˜ìœ„ ì§‘í•©ì— ëŒ€í•´ ëª‡ ê°€ì§€ ì • ì„±ì  ì‹¤í—˜ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.


For each song, we searched for similar songs by measuring the cosine similarity between the predicted usage patterns. 
ê° ë…¸ë˜ì— ëŒ€í•´ ì˜ˆì¸¡ ëœ ì‚¬ìš© íŒ¨í„´ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ì—¬ ìœ ì‚¬í•œ ë…¸ë˜ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.

We compared the usage patterns predicted using the latent factors obtained with WMF (50 dimensions), with those using latent factors predicted with a convolutional neural network. 
WMF (50 ì°¨ì›)ë¡œ ì–»ì€ ì ì¬ ì¸ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ í•œ ì‚¬ìš© íŒ¨í„´ê³¼ ì»¨ë²Œë£¨ì…˜ ì‹ ê²½ë§ìœ¼ë¡œ ì˜ˆì¸¡ í•œ ì ì¬ ì¸ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ í•œ ì‚¬ìš© íŒ¨í„´ì„ ë¹„êµí–ˆìŠµë‹ˆë‹¤.

![T4](./image/T4.PNG)
A few songs and their closest matches according to both models are shown in Table 4. 
ë‘ ëª¨ë¸ì— ë”°ë¥¸ ëª‡ ê³¡ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ê³¡ì´ í‘œ 4ì— ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤.


When the predicted latent factors are used, the matches are mostly different, but the results are quite reasonable in the sense that the matched songs are likely to appeal to the same audience. 
ì˜ˆì¸¡ ëœ ì ì¬ ìš”ì¸ì„ í™œìš©í•˜ë©´ ê²½ê¸°ê°€ ëŒ€ë¶€ë¶„ ë‹¤ë¥´ì§€ë§Œ ì¼ì¹˜í•˜ëŠ” ê³¡ì´ ê°™ì€ ì²­ì¤‘ì—ê²Œ ì–´í•„ í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ëŠ” ì ì—ì„œ ê²°ê³¼ëŠ” ìƒë‹¹íˆ í•©ë¦¬ì ì´ë‹¤.


Furthermore, they seem to be a bit more varied, which is a useful property for recommender systems.
ë”ìš±ì´ ê·¸ê²ƒë“¤ì€ ì¢€ ë” ë‹¤ì–‘í•´ ë³´ì´ëŠ”ë°, ì´ê²ƒì€ ì¶”ì²œ ì‹œìŠ¤í…œì— ìœ ìš©í•œ ì†ì„±ì…ë‹ˆë‹¤.


Following McFee et al. [5], we also visualized the distribution of predicted usage patterns in two dimensions using t-SNE [27]. 
McFee et al. [5], t-SNEë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ëœ ì‚¬ìš© íŒ¨í„´ì˜ ë¶„í¬ë¥¼ 2 ì°¨ì›ìœ¼ë¡œ ì‹œê°í™”í–ˆìŠµë‹ˆë‹¤ [27].

![Fig1](./image/Fig1.PNG)

A few close-ups are shown in Figure 1. 
ê·¸ë¦¼ 1ì—ëŠ” ëª‡ ê°€ì§€ í´ë¡œì¦ˆì—…ì´ ë‚˜ì™€ ìˆìŠµë‹ˆë‹¤.


Clusters of songs that appeal to the same audience seem to be preserved quite well, even though the latent factor vectors for all songs were predicted from audio.
ëª¨ë“  ë…¸ë˜ì˜ ì ì¬ ìš”ì†Œ ë²¡í„°ê°€ ì˜¤ë””ì˜¤ì—ì„œ ì˜ˆì¸¡ ë˜ì—ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ë™ì¼í•œ ì²­ì¤‘ì—ê²Œ í˜¸ì†Œí•˜ëŠ” ë…¸ë˜ ëª¨ìŒì€ ê½¤ ì˜ ë³´ì¡´ ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤.

---

### 6. Related work


Many researchers have attempted to mitigate the cold start problem in collaborative filtering by incorporating content-based features. 
ë§ì€ ì—°êµ¬ìë“¤ì´ ì½˜í…ì¸  ê¸°ë°˜ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ í˜‘ì—… í•„í„°ë§ì˜ ì½œë“œ ìŠ¤íƒ€íŠ¸ â€‹â€‹ë¬¸ì œë¥¼ ì™„í™”í•˜ë ¤ê³  ì‹œë„í–ˆìŠµë‹ˆë‹¤.


We review some recent work in this area of research. 
ì´ ì—°êµ¬ ë¶„ì•¼ì˜ ìµœê·¼ ì—°êµ¬ë¥¼ ê²€í† í•©ë‹ˆë‹¤.


Wang et al. [28] extend probabilistic matrix factorization (PMF) [29] with a topic model prior on the latent factor vectors of the items, and apply this model to scientific article recommendation. 
Wang et al. [28] í•­ëª©ì˜ ì ì¬ ì¸ì ë²¡í„°ì— ì•ì„œ ì£¼ì œ ëª¨ë¸ë¡œ PMF (probabilistic matrix factorization) [29]ë¥¼ í™•ì¥í•˜ê³ ì´ ëª¨ë¸ì„ ê³¼í•™ ë…¼ë¬¸ ì¶”ì²œì— ì ìš©í•©ë‹ˆë‹¤.


Topic proportions obtained from the content of the articles are used instead of latent factors when no usage data is available. 
ì‚¬ìš© ë°ì´í„°ê°€ì—†ëŠ” ê²½ìš° ê¸°ì‚¬ ë‚´ìš©ì—ì„œ ì–»ì€ ì£¼ì œ ë¹„ìœ¨ì´ ì ì¬ ìš”ì¸ ëŒ€ì‹  ì‚¬ìš©ë©ë‹ˆë‹¤.


The entire system is trained jointly, allowing the topic model and the latent space learned by matrix factorization to adapt to each other. 
ì „ì²´ ì‹œìŠ¤í…œì€ ê³µë™ìœ¼ë¡œ í›ˆë ¨ë˜ì–´ ë§¤íŠ¸ë¦­ìŠ¤ ë¶„í•´ë¡œ í•™ìŠµ ëœ ì£¼ì œ ëª¨ë¸ê³¼ ì ì¬ ê³µê°„ì´ ì„œë¡œ ì ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


Our approach is sequential instead: we first obtain latent factor vectors for songs for which usage data is available, and use these to train a regression model. 
ëŒ€ì‹  ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ ìˆœì°¨ì ì…ë‹ˆë‹¤. ë¨¼ì € ì‚¬ìš© ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ìˆëŠ” ë…¸ë˜ì— ëŒ€í•œ ì ì¬ ì¸ì ë²¡í„°ë¥¼ ì–»ê³ ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒê·€ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.


Because we reduce the incorporation of content information to a regression problem, we are able to use a deep convolutional network.
íšŒê·€ ë¬¸ì œì— ëŒ€í•œ ì½˜í…ì¸  ì •ë³´ì˜ í†µí•©ì„ ì¤„ì´ê¸° ë•Œë¬¸ì— ì‹¬ì¸µ ì»¨ë³¼ ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

McFee et al. [5] define an artist-level content-based similarity measure for music learned from a sample of collaborative filter data using metric learning to rank [21]. 
McFee et al. [5] ë­í¬ë¥¼ìœ„í•œ ë©”íŠ¸ë¦­ í•™ìŠµì„ ì‚¬ìš©í•˜ì—¬ í˜‘ì—… í•„í„° ë°ì´í„° ìƒ˜í”Œì—ì„œ í•™ìŠµ í•œ ìŒì•…ì— ëŒ€í•œ ì•„í‹°ìŠ¤íŠ¸ ìˆ˜ì¤€ì˜ ì½˜í…ì¸  ê¸°ë°˜ ìœ ì‚¬ì„± ì¸¡ì •ì„ ì •ì˜í•©ë‹ˆë‹¤ [21].


They use a variation on the typical bag-of-words approach for audio feature extraction (see section 4.1). 
ê·¸ë“¤ì€ ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œì„ ìœ„í•´ ì „í˜•ì ì¸ bag-of-words ì ‘ê·¼ë²•ì˜ ë³€í˜•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (ì„¹ì…˜ 4.1 ì°¸ì¡°).


Their results corroborate that relying on usage data to train the model improves content-based recommendations. 
ê·¸ë“¤ì˜ ê²°ê³¼ëŠ” ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•´ ì‚¬ìš© ë°ì´í„°ì— ì˜ì¡´í•˜ëŠ” ê²ƒì´ ì½˜í…ì¸  ê¸°ë°˜ ê¶Œì¥ ì‚¬í•­ì„ ê°œì„ í•œë‹¤ëŠ” ê²ƒì„ ì…ì¦í•©ë‹ˆë‹¤.


For audio data they used the CAL10K dataset, which consists of 10,832 songs, so it is comparable in size to the subset of the MSD that we used for our initial experiments. 
ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ê²½ìš° 10,832 ê³¡ìœ¼ë¡œ êµ¬ì„±ëœ CAL10K ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— ì´ˆê¸° ì‹¤í—˜ì— ì‚¬ìš©í•œ MSDì˜ í•˜ìœ„ ì§‘í•©ê³¼ í¬ê¸°ê°€ ë¹„ìŠ·í•©ë‹ˆë‹¤.


Weston et al. [17] investigate the problem of recommending items to a user given another item as a query, which they call â€˜collaborative retrievalâ€™. 
Weston et al. [17] ë‹¤ë¥¸ í•­ëª©ì´ ì¿¼ë¦¬ë¡œ ì£¼ì–´ì§€ë©´ ì‚¬ìš©ìì—ê²Œ í•­ëª©ì„ ì¶”ì²œí•˜ëŠ” ë¬¸ì œë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤.ì´ë¥¼ 'í˜‘ì—… ê²€ìƒ‰'ì´ë¼ê³ í•©ë‹ˆë‹¤.


They optimize an item scoring function using a ranking loss and describe a variant of their method that allows for content features to be incorporated. 
ìˆœìœ„ ì†ì‹¤ì„ ì‚¬ìš©í•˜ì—¬ í•­ëª© ì ìˆ˜ ê¸°ëŠ¥ì„ ìµœì í™”í•˜ê³  ì½˜í…ì¸  ê¸°ëŠ¥ì„ í†µí•© í•  ìˆ˜ìˆëŠ” ë°©ë²•ì˜ ë³€í˜•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.


They also use the bag-of-words approach to extract audio features and evaluate this method on a large proprietary dataset. 
ê·¸ë“¤ì€ ë˜í•œ bag-of-words ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ê¸°ëŠ¥ì„ ì¶”ì¶œí•˜ê³  ëŒ€ê·œëª¨ ë…ì  ë°ì´í„° ì„¸íŠ¸ì—ì„œì´ ë°©ë²•ì„ í‰ê°€í•©ë‹ˆë‹¤.


They find that combining collaborative filtering and content-based information does not improve the accuracy of the recommendations over collaborative filtering alone.
ê·¸ë“¤ì€ í˜‘ì—… í•„í„°ë§ê³¼ ì½˜í…ì¸  ê¸°ë°˜ ì •ë³´ë¥¼ ê²°í•©í•œë‹¤ê³ í•´ì„œ í˜‘ì—… í•„í„°ë§ë§Œìœ¼ë¡œëŠ” ê¶Œì¥ ì‚¬í•­ì˜ ì •í™•ì„±ì´ í–¥ìƒë˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ ì•Œê²Œë˜ì—ˆìŠµë‹ˆë‹¤.


Both McFee et al. and Weston et al. optimized their models using a ranking loss. 
McFee et al. ë° Weston et al. ìˆœìœ„ ì†ì‹¤ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ìµœì í™”í–ˆìŠµë‹ˆë‹¤.


We have opted to use quadratic loss functions instead, because we found their optimization to be more easily scalable. 
ëŒ€ì‹  2 ì°¨ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. ìµœì í™”ê°€ ë” ì‰½ê²Œ í™•ì¥ ê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒì„ ì•Œì•˜ ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

Using a ranking loss instead is an interesting direction of future research, although we suspect that this approach may suffer from the same problems as the WPE objective (i.e. popular songs will have an unfair advantage).
ìˆœìœ„ ì†ì‹¤ì„ ëŒ€ì‹  ì‚¬ìš©í•˜ëŠ” ê²ƒì€ í–¥í›„ ì—°êµ¬ì˜ í¥ë¯¸ë¡œìš´ ë°©í–¥ì´ì§€ë§Œ,ì´ ì ‘ê·¼ ë°©ì‹ì€ WPE ëª©í‘œì™€ ë™ì¼í•œ ë¬¸ì œ (ì¦‰, ì¸ê¸°ìˆëŠ” ë…¸ë˜ê°€ ë¶ˆê³µì • í•œ ì´ì ì„ ê°€ì§ˆ ìˆ˜ ìˆìŒ)ë¥¼ ê²ªì„ ìˆ˜ ìˆë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.

---

### 7. Conclusion

In this paper, we have investigated the use of deep convolutional neural networks to predict latent factors from music audio when they cannot be obtained from usage data. 
ì´ ë…¼ë¬¸ì—ì„œëŠ” ì‚¬ìš© ë°ì´í„°ì—ì„œ ì–»ì„ ìˆ˜ì—†ëŠ” ìŒì•… ì˜¤ë””ì˜¤ì˜ ì ì¬ ìš”ì¸ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì‹¬ì¸µ ì»¨ë³¼ ë£¨ì…˜ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤.


We evaluated the predictions by using them for music recommendation on an industrial-scale dataset. 
ìš°ë¦¬ëŠ” ì‚°ì—… ê·œëª¨ì˜ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ìŒì•… ì¶”ì²œì— ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.


Even though a lot of characteristics of songs that affect user preference cannot be predicted from audio signals, the resulting recommendations seem to be sensible. 
ì‚¬ìš©ì ì„ í˜¸ë„ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë…¸ë˜ì˜ ë§ì€ íŠ¹ì„±ì€ ì˜¤ë””ì˜¤ ì‹ í˜¸ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ì—†ì§€ë§Œ ê²°ê³¼ì ìœ¼ë¡œ ì¶”ì²œí•˜ëŠ” ê²ƒì€ í•©ë¦¬ì ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.


We can conclude that predicting latent factors from music audio is a viable method for recommending new and unpopular music.
ìŒì•… ì˜¤ë””ì˜¤ì˜ ì ì¬ ìš”ì¸ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ìƒˆë¡­ê³  ì¸ê¸°ì—†ëŠ” ìŒì•…ì„ ì¶”ì²œí•˜ëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ ë°©ë²•ì´ë¼ëŠ” ê²°ë¡ ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


We also showed that recent advances in deep learning translate very well to the music recommendation setting in combination with this approach, with deep convolutional neural networks significantly outperforming a more traditional approach using bag-of-words representations of audio signals. 
ë˜í•œ ìµœê·¼ ë”¥ ëŸ¬ë‹ì˜ ë°œì „ì€ ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ê³¼ ê²°í•©í•˜ì—¬ ìŒì•… ì¶”ì²œ ì„¤ì •ìœ¼ë¡œ ë§¤ìš° ì˜ ë³€í™˜ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ì‹¬ì¸µ ì»¨ë³¼ ë£¨ì…˜ ì‹ ê²½ë§ì€ ì˜¤ë””ì˜¤ ì‹ í˜¸ì˜ ë‹¨ì–´ ëª¨ìŒ í‘œí˜„ì„ ì‚¬ìš©í•˜ëŠ”ë³´ë‹¤ ì „í†µì ì¸ ì ‘ê·¼ ë°©ì‹ì„ í›¨ì”¬ ëŠ¥ê°€í•©ë‹ˆë‹¤.


This bag-of-words representation is used very often in MIR, and our results indicate that a lot of research in this domain could benefit significantly from using deep neural networks.
ì´ bag-of-words í‘œí˜„ì€ MIRì—ì„œ ë§¤ìš° ìì£¼ ì‚¬ìš©ë˜ë©°, ìš°ë¦¬ì˜ ê²°ê³¼ëŠ”ì´ ì˜ì—­ì˜ ë§ì€ ì—°êµ¬ê°€ ì‹¬ì¸µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ìƒë‹¹í•œ ì´ì ì„ ì–»ì„ ìˆ˜ ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.


---